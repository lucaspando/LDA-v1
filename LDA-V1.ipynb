{"cells":[{"cell_type":"code","source":["#Example following this post: https://towardsdatascience.com/nlp-extracting-the-main-topics-from-your-dataset-using-lda-in-minutes-21486f5aa925"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["from sklearn.datasets import fetch_20newsgroups\nnewsgroups_train = fetch_20newsgroups(subset='train', shuffle = True)\nnewsgroups_test = fetch_20newsgroups(subset='test', shuffle = True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["print(list(newsgroups_train.target_names))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&apos;alt.atheism&apos;, &apos;comp.graphics&apos;, &apos;comp.os.ms-windows.misc&apos;, &apos;comp.sys.ibm.pc.hardware&apos;, &apos;comp.sys.mac.hardware&apos;, &apos;comp.windows.x&apos;, &apos;misc.forsale&apos;, &apos;rec.autos&apos;, &apos;rec.motorcycles&apos;, &apos;rec.sport.baseball&apos;, &apos;rec.sport.hockey&apos;, &apos;sci.crypt&apos;, &apos;sci.electronics&apos;, &apos;sci.med&apos;, &apos;sci.space&apos;, &apos;soc.religion.christian&apos;, &apos;talk.politics.guns&apos;, &apos;talk.politics.mideast&apos;, &apos;talk.politics.misc&apos;, &apos;talk.religion.misc&apos;]\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Lets look at some sample news\nnewsgroups_train.data[:2]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>\n[&quot;From: lerxst@wam.umd.edu (where&apos;s my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n&quot;,\n &quot;From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven&apos;t answered this\\npoll. Thanks.\\n\\nGuy Kuo &lt;guykuo@u.washington.edu&gt;\\n&quot;]\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["print (type(newsgroups_train))\nprint(dir(newsgroups_train))\nprint(newsgroups_train.filenames.shape, newsgroups_train.target.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &apos;sklearn.datasets.base.Bunch&apos;&gt;\n[&apos;DESCR&apos;, &apos;data&apos;, &apos;description&apos;, &apos;filenames&apos;, &apos;target&apos;, &apos;target_names&apos;]\n(11314,) (11314,)\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["import nltk\nnltk.download('wordnet')\n\n'''\nLoading Gensim and nltk libraries\n'''\n# pip install gensim\nimport gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom nltk.stem.porter import *\nimport numpy as np\nnp.random.seed(400)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[nltk_data] Downloading package wordnet to /root/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\nparamiko missing, opening SSH/SCP/SFTP paths will be disabled.  &#96;pip install paramiko&#96; to suppress\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["print(WordNetLemmatizer().lemmatize('went', pos = 'v')) # past tense to present tense"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">go\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["import pandas as pd\nstemmer = SnowballStemmer(\"english\")\noriginal_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n           'traditional', 'reference', 'colonizer','plotted']\nsingles = [stemmer.stem(plural) for plural in original_words]\n\npd.DataFrame(data={'original word':original_words, 'stemmed':singles })"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">25</span><span class=\"ansired\">]: </span>\n   original word stemmed\n0       caresses  caress\n1          flies     fli\n2           dies     die\n3          mules    mule\n4         denied    deni\n5           died     die\n6         agreed    agre\n7          owned     own\n8        humbled   humbl\n9          sized    size\n10       meeting    meet\n11       stating   state\n12       siezing    siez\n13   itemization    item\n14   sensational  sensat\n15   traditional  tradit\n16     reference   refer\n17     colonizer   colon\n18       plotted    plot\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["'''\nWrite a function to perform the pre processing steps on the entire dataset\n'''\ndef lemmatize_stemming(text):\n    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n\n# Tokenize and lemmatize\ndef preprocess(text):\n    result=[]\n    for token in gensim.utils.simple_preprocess(text) :\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n            result.append(lemmatize_stemming(token))\n            \n    return result"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["'''\nPreview a document after preprocessing\n'''\ndocument_num = 50\ndoc_sample = 'This disk has failed many times. I would like to get it replaced.'\n\nprint(\"Original document: \")\nwords = []\nfor word in doc_sample.split(' '):\n    words.append(word)\nprint(words)\nprint(\"\\n\\nTokenized and lemmatized document: \")\nprint(preprocess(doc_sample))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Original document: \n[&apos;This&apos;, &apos;disk&apos;, &apos;has&apos;, &apos;failed&apos;, &apos;many&apos;, &apos;times.&apos;, &apos;I&apos;, &apos;would&apos;, &apos;like&apos;, &apos;to&apos;, &apos;get&apos;, &apos;it&apos;, &apos;replaced.&apos;]\n\n\nTokenized and lemmatized document: \n[&apos;disk&apos;, &apos;fail&apos;, &apos;time&apos;, &apos;like&apos;, &apos;replac&apos;]\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["processed_docs = []\n\nfor doc in newsgroups_train.data:\n    processed_docs.append(preprocess(doc))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["'''\nCreate a dictionary from 'processed_docs' containing the number of times a word appears \nin the training set using gensim.corpora.Dictionary and call it 'dictionary'\n'''\ndictionary = gensim.corpora.Dictionary(processed_docs)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"code","source":["'''\nChecking dictionary created\n'''\ncount = 0\nfor k, v in dictionary.iteritems():\n    print(k, v)\n    count += 1\n    if count > 10:\n        break"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">30542 mcghee\n52757 icnl\n32476 camarillo\n50071 unform\n28099 mccovey\n8251 ravikumar\n28608 ununsu\n32873 prenat\n7935 irrat\n56705 ormat\n37136 raitanen\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["'''\nOPTIONAL STEP\nRemove very rare and very common words:\n\n- words appearing less than 15 times\n- words appearing in more than 10% of all documents\n'''\ndictionary.filter_extremes(no_below=15, no_above=0.1, keep_n= 100000)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["'''\nCreate the Bag-of-words model for each document i.e for each document we create a dictionary reporting how many\nwords and how many times those words appear. Save this to 'bow_corpus'\n'''\nbow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["'''\nPreview BOW for our sample preprocessed document\n'''\ndocument_num = 20\nbow_doc_x = bow_corpus[document_num]\n\nfor i in range(len(bow_doc_x)):\n    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n                                                     dictionary[bow_doc_x[i][0]], \n                                                     bow_doc_x[i][1]))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Word 18 (&quot;rest&quot;) appears 1 time.\nWord 166 (&quot;clear&quot;) appears 1 time.\nWord 336 (&quot;refer&quot;) appears 1 time.\nWord 350 (&quot;true&quot;) appears 1 time.\nWord 391 (&quot;technolog&quot;) appears 1 time.\nWord 437 (&quot;christian&quot;) appears 1 time.\nWord 453 (&quot;exampl&quot;) appears 1 time.\nWord 476 (&quot;jew&quot;) appears 1 time.\nWord 480 (&quot;lead&quot;) appears 1 time.\nWord 482 (&quot;littl&quot;) appears 3 time.\nWord 520 (&quot;wors&quot;) appears 2 time.\nWord 721 (&quot;keith&quot;) appears 3 time.\nWord 732 (&quot;punish&quot;) appears 1 time.\nWord 803 (&quot;california&quot;) appears 1 time.\nWord 859 (&quot;institut&quot;) appears 1 time.\nWord 917 (&quot;similar&quot;) appears 1 time.\nWord 990 (&quot;allan&quot;) appears 1 time.\nWord 991 (&quot;anti&quot;) appears 1 time.\nWord 992 (&quot;arriv&quot;) appears 1 time.\nWord 993 (&quot;austria&quot;) appears 1 time.\nWord 994 (&quot;caltech&quot;) appears 2 time.\nWord 995 (&quot;distinguish&quot;) appears 1 time.\nWord 996 (&quot;german&quot;) appears 1 time.\nWord 997 (&quot;germani&quot;) appears 3 time.\nWord 998 (&quot;hitler&quot;) appears 1 time.\nWord 999 (&quot;livesey&quot;) appears 2 time.\nWord 1000 (&quot;motto&quot;) appears 2 time.\nWord 1001 (&quot;order&quot;) appears 1 time.\nWord 1002 (&quot;pasadena&quot;) appears 1 time.\nWord 1003 (&quot;pompous&quot;) appears 1 time.\nWord 1004 (&quot;popul&quot;) appears 1 time.\nWord 1005 (&quot;rank&quot;) appears 1 time.\nWord 1006 (&quot;schneider&quot;) appears 1 time.\nWord 1007 (&quot;semit&quot;) appears 1 time.\nWord 1008 (&quot;social&quot;) appears 1 time.\nWord 1009 (&quot;solntz&quot;) appears 1 time.\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["# LDA mono-core -- fallback code in case LdaMulticore throws an error on your machine\n# lda_model = gensim.models.LdaModel(bow_corpus, \n#                                    num_topics = 10, \n#                                    id2word = dictionary,                                    \n#                                    passes = 50)\n\n# LDA multicore \n'''\nTrain your lda model using gensim.models.LdaMulticore and save it to 'lda_model'\n'''\n# TODO\nlda_model =  gensim.models.LdaMulticore(bow_corpus, \n                                   num_topics = 8, \n                                   id2word = dictionary,                                    \n                                   passes = 10,\n                                   workers = 2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["\n'''\nFor each topic, we will explore the words occuring in that topic and its relative weight\n'''\nfor idx, topic in lda_model.print_topics(-1):\n    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n    print(\"\\n\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Topic: 0 \nWords: 0.008*&quot;bike&quot; + 0.006*&quot;game&quot; + 0.005*&quot;team&quot; + 0.004*&quot;run&quot; + 0.004*&quot;player&quot; + 0.004*&quot;virginia&quot; + 0.004*&quot;play&quot; + 0.004*&quot;pitch&quot; + 0.004*&quot;homosexu&quot; + 0.003*&quot;defens&quot;\n\n\nTopic: 1 \nWords: 0.009*&quot;govern&quot; + 0.007*&quot;armenian&quot; + 0.006*&quot;israel&quot; + 0.005*&quot;kill&quot; + 0.005*&quot;isra&quot; + 0.004*&quot;american&quot; + 0.004*&quot;turkish&quot; + 0.004*&quot;countri&quot; + 0.004*&quot;weapon&quot; + 0.004*&quot;live&quot;\n\n\nTopic: 2 \nWords: 0.016*&quot;game&quot; + 0.013*&quot;team&quot; + 0.011*&quot;play&quot; + 0.009*&quot;hockey&quot; + 0.008*&quot;player&quot; + 0.005*&quot;canada&quot; + 0.005*&quot;season&quot; + 0.004*&quot;leagu&quot; + 0.004*&quot;score&quot; + 0.004*&quot;andrew&quot;\n\n\nTopic: 3 \nWords: 0.010*&quot;card&quot; + 0.010*&quot;window&quot; + 0.008*&quot;driver&quot; + 0.007*&quot;sale&quot; + 0.006*&quot;price&quot; + 0.005*&quot;speed&quot; + 0.005*&quot;appl&quot; + 0.005*&quot;monitor&quot; + 0.005*&quot;video&quot; + 0.005*&quot;engin&quot;\n\n\nTopic: 4 \nWords: 0.014*&quot;file&quot; + 0.010*&quot;program&quot; + 0.009*&quot;window&quot; + 0.006*&quot;encrypt&quot; + 0.006*&quot;chip&quot; + 0.006*&quot;imag&quot; + 0.006*&quot;data&quot; + 0.006*&quot;avail&quot; + 0.005*&quot;version&quot; + 0.004*&quot;code&quot;\n\n\nTopic: 5 \nWords: 0.012*&quot;space&quot; + 0.009*&quot;nasa&quot; + 0.006*&quot;scienc&quot; + 0.005*&quot;orbit&quot; + 0.004*&quot;research&quot; + 0.004*&quot;launch&quot; + 0.003*&quot;pitt&quot; + 0.003*&quot;earth&quot; + 0.003*&quot;develop&quot; + 0.003*&quot;bank&quot;\n\n\nTopic: 6 \nWords: 0.032*&quot;drive&quot; + 0.015*&quot;scsi&quot; + 0.010*&quot;disk&quot; + 0.009*&quot;hard&quot; + 0.008*&quot;control&quot; + 0.007*&quot;columbia&quot; + 0.007*&quot;washington&quot; + 0.006*&quot;uiuc&quot; + 0.005*&quot;car&quot; + 0.004*&quot;jumper&quot;\n\n\nTopic: 7 \nWords: 0.012*&quot;christian&quot; + 0.008*&quot;jesus&quot; + 0.006*&quot;exist&quot; + 0.005*&quot;word&quot; + 0.005*&quot;moral&quot; + 0.005*&quot;bibl&quot; + 0.005*&quot;religion&quot; + 0.004*&quot;life&quot; + 0.004*&quot;church&quot; + 0.004*&quot;claim&quot;\n\n\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["num = 100\nunseen_document = newsgroups_test.data[num]\nprint(unseen_document)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Subject: help\nFrom: C..Doelle@p26.f3333.n106.z1.fidonet.org (C. Doelle)\nLines: 13\n\nHello All!\n\n    It is my understanding that all True-Type fonts in Windows are loaded in\nprior to starting Windows - this makes getting into Windows quite slow if you\nhave hundreds of them as I do.  First off, am I correct in this thinking -\nsecondly, if that is the case - can you get Windows to ignore them on boot and\nmaybe make something like a PIF file to load them only when you enter the\napplications that need fonts?  Any ideas?\n\n\nChris\n\n * Origin: chris.doelle.@f3333.n106.z1.fidonet.org (1:106/3333.26)\n\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["# Data preprocessing step for the unseen document\nbow_vector = dictionary.doc2bow(preprocess(unseen_document))\n\nfor index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Score: 0.604105532169342\t Topic: 0.010*&quot;card&quot; + 0.010*&quot;window&quot; + 0.008*&quot;driver&quot; + 0.007*&quot;sale&quot; + 0.006*&quot;price&quot;\nScore: 0.3716551959514618\t Topic: 0.014*&quot;file&quot; + 0.010*&quot;program&quot; + 0.009*&quot;window&quot; + 0.006*&quot;encrypt&quot; + 0.006*&quot;chip&quot;\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["print(newsgroups_test.target[num])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2\n</div>"]}}],"execution_count":21}],"metadata":{"name":"LDA-V1","notebookId":1673356984597560},"nbformat":4,"nbformat_minor":0}
